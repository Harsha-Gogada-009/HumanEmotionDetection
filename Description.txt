Facial Emotion Recognition - Project Overview
This project aims to build a CNN-based deep learning model for facial emotion recognition using PyTorch. Below is a breakdown of how each file contributes to the overall model:

ğŸ“‚ 1. generate_data.ipynb
Purpose: Prepares the dataset for training and validation.

Key Functions:
âœ… Reads the original train.csv, which contains pixel values of images.
âœ… Splits the dataset into train.csv (for training) and val.csv (for validation).
âœ… Converts pixel data into 48Ã—48 grayscale images and stores them in respective folders:

ğŸ“ train/ â†’ Training images (e.g., train4.jpg â†’ Label 4)
ğŸ“ val/ â†’ Validation images
ğŸ§  2. deep_emotion.ipynb
Purpose: Defines Deep_Emotion, a CNN-based model for facial emotion classification.

Model Architecture:
ğŸ”¹ Convolutional Layers â€“ Extract meaningful features from images.
ğŸ”¹ Batch Normalization & Pooling â€“ Improve training stability and reduce dimensionality.
ğŸ”¹ Fully Connected Layers â€“ Classify emotions into 7 categories.
ğŸ”¹ Spatial Transformer Network (STN) â€“ Aligns facial features for better accuracy.

ğŸ‘‰ The model learns spatial transformations, deep feature extraction, and emotion classification.

ğŸ“œ 3. data_loaders.ipynb
Purpose: Loads and preprocesses image data using PyTorch.

Components:
ğŸ“Œ Plain_Dataset (PyTorch Dataset class)

Reads image paths and labels from a CSV file.
Applies transformations (e.g., normalization).
Returns image & corresponding label when indexed.
ğŸ“Œ Helper Function (eval_data_dataloader)

Loads and displays an image with its label.
Uses Matplotlib to visualize a sample image (e.g., index 10).
ğŸ‘‰ This script ensures seamless image loading & preprocessing for training.

ğŸ¯ 4. main.ipynb
Purpose: The core training and evaluation script for the model.

Workflow:
ğŸ”¹ Data Preprocessing:
âœ” Loads dataset utilities (Plain_Dataset, eval_data_dataloader).
âœ” Applies grayscale conversion, tensor transformation, and normalization.
âœ” Creates DataLoaders for batch processing.

ğŸ”¹ Model Training:
âœ” Loads the Deep_Emotion model and moves it to GPU (if available).
âœ” Uses CrossEntropyLoss and Adam optimizer.
âœ” Trains the model for 50 epochs, printing loss per epoch.
âœ” Saves the trained model as "deep_emotion_model.pth".

ğŸ”¹ Model Evaluation:
âœ” Loads the trained model and sets it to evaluation mode.
âœ” Computes validation accuracy on unseen data.
âœ” Outputs the training loss per epoch and the final validation accuracy.

ğŸ“Œ Experimentation:
You can tweak the following hyperparameters to optimize performance:
âœ… Number of epochs
âœ… Learning rates
âœ… Dropout layers
âœ… Different optimizers (e.g., SGD, RMSprop)
âœ… Loss functions

ğŸš€ Final Output:
âœ… Trained emotion classification model ğŸ­
âœ… Performance metrics & validation accuracy ğŸ“Š
âœ… Optimized for real-world facial emotion recognition ğŸ¤–
